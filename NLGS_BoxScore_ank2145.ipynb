{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ank2809/NLGS-BoxScore/blob/main/NLGS_BoxScore_ank2145.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Only if running in Colab\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l-mEMqpKsF86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4qxRGlJrGS8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Data Processing**"
      ],
      "metadata": {
        "id": "4DH4vSoFsSNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All cells in this section have to be run for the model to work."
      ],
      "metadata": {
        "id": "7xQZnVkYv1wK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Reading the Data"
      ],
      "metadata": {
        "id": "SZEKQ2OZtGPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The source can be 'rotowire' (professional summaries) or 'sbnation' (fan-written summaries). I primarily used RotoWire.\n",
        "\n",
        "The path points to the directory containing the data."
      ],
      "metadata": {
        "id": "1Au3dmJJsdPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1JA_olDrUV_"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3MhH32nrV86"
      },
      "outputs": [],
      "source": [
        "def read_data(source, path):\n",
        "  # source is one of 'rotowire' and 'sbnation'\n",
        "  # path points to the directory containing the data, 'drive/MyDrive' in this case.\n",
        "  filer = open(path + source + '/train.json')\n",
        "  data_train = json.load(filer)\n",
        "  filer = open('drive/MyDrive/' + source + '/valid.json')\n",
        "  data_valid = json.load(filer)\n",
        "  filer = open('drive/MyDrive/' + source + '/test.json')\n",
        "  data_test = json.load(filer)\n",
        "  return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Parsing the Data"
      ],
      "metadata": {
        "id": "YPM8VNWmtKlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNsi0-_2LZ6Z"
      },
      "outputs": [],
      "source": [
        "def extract_data(map, category, key):\n",
        "  value = map[category][key]\n",
        "  if value.isnumeric():\n",
        "    return int(value)\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the primary function to create the labelled datasets from the raw data. X and Y are the datasets for the first stage of the model.\n",
        "X2 and Y2 are the datasets for the second stage of the model."
      ],
      "metadata": {
        "id": "aQyiGDZ1tPas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3D6_EEurqkQ"
      },
      "outputs": [],
      "source": [
        "common_fix = {'Stephen Curry': 'Steph Curry'}\n",
        "\n",
        "def create_datasets(players, mentioned, X, Y, data, X2, Y2, max_rows = 10):\n",
        "  ## Stores data for Stage 1 (SELECT) in X and Y. X is a list of vectors representing\n",
        "  ## box score rows and Y is a list of corresponding binary labels\n",
        "\n",
        "  ## Stores data for Stage 1 (GENERATE) in X2 and Y2. X2 is a list of box score\n",
        "  ## data from each game that should be included in the summary. Y2 is a list\n",
        "  ## actual game summaries\n",
        "\n",
        "  ## We use max_rows to determine how many games we want to work with\n",
        "  ## I have set it to a low number to ensure it's easy for TAs to verify the code.\n",
        "  ## Otherwise, the second stage of the model will take hours to run.\n",
        "\n",
        "  categories = ['PTS', 'REB', 'AST', 'STL', 'BLK', 'TO']\n",
        "  count = 0\n",
        "\n",
        "  for i in data:\n",
        "    \n",
        "    date = i['day'].split('_')\n",
        "    year = date[2]\n",
        "    month = date[0]\n",
        "    day = date[1]\n",
        "    date = year + '_' + month + '_' + day\n",
        "\n",
        "    check = (int)(month)\n",
        "    check2 = (int)(day)\n",
        "    check3 = (int)(year)\n",
        "    if (check < 10 and check > 4) or (check == 10 and check2 <= 25) or (check == 4 and check2 >= 15):\n",
        "      continue\n",
        "    count+=1\n",
        "  \n",
        "    # Uncomment these lines if you want to watch the function run\n",
        "    # if count % 100 == 0:\n",
        "    #   print(count)\n",
        "\n",
        "    if count % max_rows == 0:\n",
        "      break\n",
        "    key = 'po'\n",
        "    if check3 == 14 or (check3 == 15 and check < 6):\n",
        "      key = '14/15'\n",
        "    elif check3 == 15 or (check3 == 16 and check < 6):\n",
        "      key = '15/16'\n",
        "    elif check3 == 16 or (check3 == 17 and check < 6):\n",
        "      key = '16/17'\n",
        "  \n",
        "    # The key and date are essential to map the box score data to the static\n",
        "    # and dynamic data.\n",
        "    \n",
        "    team1 = i['home_city'] + ' ' + i['home_name']\n",
        "    team2 = i['vis_city'] + ' ' + i['vis_name']\n",
        "\n",
        "    team1_pts = i['home_line']['TEAM-PTS']\n",
        "    team2_pts = i['vis_line']['TEAM-PTS']\n",
        "\n",
        "    if (team2_pts > team1_pts):\n",
        "      tmp = team1\n",
        "      team1 = team2\n",
        "      team2 = tmp\n",
        "\n",
        "      tmp = team1_pts\n",
        "      team1_pts = team2_pts\n",
        "      team2_pts = tmp\n",
        "\n",
        "    mentions = set(i['summary'])\n",
        "    text = ' '.join(i['summary'])\n",
        "    Y2.append(text)\n",
        "    x2 = [[team1, team2, team1_pts, team2_pts, date, key]]\n",
        "   \n",
        "    player_names = i['box_score']['PLAYER_NAME']\n",
        "  \n",
        "    for k in player_names.keys():\n",
        "      if len(X) != len(Y):\n",
        "        print(count)\n",
        "        break\n",
        "      name = player_names[k]\n",
        "\n",
        "      if name in common_fix:\n",
        "        name = common_fix[name]\n",
        "\n",
        "      if name not in players:\n",
        "        mentioned[name] = 0\n",
        "        players.add(name)\n",
        "\n",
        "      x = [name]\n",
        "      \n",
        "      min = i['box_score']['MIN'][k]\n",
        "      if not min.isnumeric():\n",
        "        # Player did not play in the game\n",
        "        for category in categories:\n",
        "          x.append(0)\n",
        "        x.append(key)\n",
        "        Y.append(0)\n",
        "        X.append(x)\n",
        "        continue\n",
        "      \n",
        "      name_arr = name.split(' ')\n",
        "      flag = True\n",
        "      for mention in name_arr:\n",
        "        if mention not in mentions:\n",
        "          flag = False\n",
        "          break\n",
        "      \n",
        "      check = True\n",
        "      for category in categories:\n",
        "        value = extract_data(i['box_score'], category, k)\n",
        "        x.append(value)\n",
        "        if flag and check and str(value) in mentions:\n",
        "          # We use mentioned to track how often players are included in summaries\n",
        "          mentioned[name]+=1\n",
        "          Y.append(1)\n",
        "          check = False\n",
        "      x.append(key)\n",
        "      X.append(x)\n",
        "      if check:\n",
        "        Y.append(0)\n",
        "      else:\n",
        "        x2.append(x)\n",
        "    X2.append(x2)\n",
        "\n",
        "  return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Cq09iOQ_qH"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid, data_test = read_data('rotowire', 'drive/MyDrive/') ## REPLACE WITH CORRECT PATH\n",
        "players = set()\n",
        "mentioned = dict()\n",
        "index = 0\n",
        "X = []\n",
        "Y = []\n",
        "X2 = []\n",
        "Y2 = []\n",
        "index = create_datasets(players, mentioned, X, Y, data_train, X2, Y2)\n",
        "\n",
        "## Uncomment these lines if we want to include all the data. Train itself has about\n",
        "## 3200 games. The full set is about 4600 games.\n",
        "\n",
        "# index = create_datasets(players, mentioned, X, Y, data_valid, X2, Y2)\n",
        "# index = create_datasets(players, mentioned, X, Y, data_test, X2, Y2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Create Placeholders for Static/Dynamic Data"
      ],
      "metadata": {
        "id": "EwgkgCESvWY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This ensures the code runs without errors even if we don't use the static/dynamic data. If we end up using the data, it will be stored in these dictionaries."
      ],
      "metadata": {
        "id": "AMXhRCyuvpUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draft = dict()\n",
        "all_stars = dict()\n",
        "final_streak = dict()\n",
        "final_record = dict()\n",
        "final_stats = dict()"
      ],
      "metadata": {
        "id": "3I0ltzVJxyBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **Create Static Data**"
      ],
      "metadata": {
        "id": "elLEGVnzvsI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is optional and should only be run if we want to include static data in both stages of the model. If it is to be used, all cells in this section\n",
        "must be run."
      ],
      "metadata": {
        "id": "BBNzpewnvw8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install basketball_reference_scraper"
      ],
      "metadata": {
        "id": "LosW5oO_wfo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from basketball_reference_scraper.drafts import get_draft_class\n",
        "from basketball_reference_scraper.box_scores import get_all_star_box_score"
      ],
      "metadata": {
        "id": "j8Me_cW4wgXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a map of rookies/All-Stars per season, that can be accessed using the season and the player name."
      ],
      "metadata": {
        "id": "MT2s1dxUwnsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conferences = ['East', 'West']\n",
        "for i in range(len(seasons)):\n",
        "  draft[seasons[i]] = set()\n",
        "  players = get_draft_class(2014 + i)['PLAYER']\n",
        "  for player in players:\n",
        "    draft[seasons[i]].add(player)\n",
        "  \n",
        "  all_stars[seasons[i]] = set()\n",
        "  players  = get_all_star_box_score(2014 + i)\n",
        "  for conference in conferences:\n",
        "    for player in players[conference]['PLAYER']:\n",
        "      if player in common_fix:\n",
        "        player = common_fix[player]\n",
        "      all_stars[seasons[i]].add(player)"
      ],
      "metadata": {
        "id": "4K53UHeKwmOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional Cells to view the data so far"
      ],
      "metadata": {
        "id": "9P9k2JLyx-9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draft"
      ],
      "metadata": {
        "id": "5lI76ijBx_kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_stars"
      ],
      "metadata": {
        "id": "YYAhYv1CyApo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. **Create Dynamic Data**"
      ],
      "metadata": {
        "id": "gsm9L_Zkwv3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is optional and should only be run if we want to include dynamic data in the second stage of the model. If it is to be used, all cells in this section must be run."
      ],
      "metadata": {
        "id": "ruExZ8TExIbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next function maps a team's wins/losses to a specific date."
      ],
      "metadata": {
        "id": "4f_j62KxxQO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCR8eYA6VDXj"
      },
      "outputs": [],
      "source": [
        "cat = ['PTS', 'REB', 'AST']\n",
        "seasons = ['14/15', '15/16', '16/17']\n",
        "def create_streaks(data, streaks, stats):\n",
        "\n",
        "  \n",
        "  count = 0\n",
        "  for i in data:\n",
        "   \n",
        "    count+=1\n",
        "\n",
        "    # If you want to keep track of how many games have been processed so far,\n",
        "    # uncomment the next two lines.\n",
        "    # if count % 100 == 0:\n",
        "    #   print(count)\n",
        "\n",
        "    team1 = i['home_city'] + ' ' + i['home_name']\n",
        "    team2 = i['vis_city'] + ' ' + i['vis_name']\n",
        "\n",
        "    team1_pts = i['home_line']['TEAM-PTS']\n",
        "    team2_pts = i['vis_line']['TEAM-PTS']\n",
        "\n",
        "    if (team2_pts > team1_pts):\n",
        "      tmp = team1\n",
        "      team1 = team2\n",
        "      team2 = tmp\n",
        "\n",
        "      tmp = team1_pts\n",
        "      team1_pts = team2_pts\n",
        "      team2_pts = tmp\n",
        "  \n",
        "    # Ensures team1 is the winning team and team2 is the losing team\n",
        "    \n",
        "    date = i['day'].split('_')\n",
        "    year = date[2]\n",
        "    month = date[0]\n",
        "    day = date[1]\n",
        "    date = year + '_' + month + '_' + day\n",
        "\n",
        "    check = (int)(month)\n",
        "    check2 = (int)(day)\n",
        "    check3 = (int)(year)\n",
        "\n",
        "    # We don't include preseason or playoff games\n",
        "    if (check < 10 and check > 4) or (check == 10 and check2 <= 25) or (check == 4 and check2 >= 15):\n",
        "      continue\n",
        "    key = 'po'\n",
        "    if check3 == 14 or (check3 == 15 and check < 6):\n",
        "      key = '14/15'\n",
        "    elif check3 == 15 or (check3 == 16 and check < 6):\n",
        "      key = '15/16'\n",
        "    elif check3 == 16 or (check3 == 17 and check < 6):\n",
        "      key = '16/17'\n",
        "    \n",
        "    if key not in streaks:\n",
        "      streaks[key] = dict()\n",
        "    \n",
        "    if team1 not in streaks[key]:\n",
        "      streaks[key][team1] = dict()\n",
        "    if team2 not in streaks[key]:\n",
        "      streaks[key][team2] = dict()\n",
        "    \n",
        "    streaks[key][team1][date] = 1\n",
        "    streaks[key][team2][date] = -1\n",
        "\n",
        "    if key not in stats:\n",
        "          stats[key] = dict()\n",
        "    \n",
        "    player_names = i['box_score']['PLAYER_NAME']\n",
        "    for k in player_names.keys():\n",
        "      name = player_names[k]\n",
        "\n",
        "      if name in common_fix:\n",
        "        name = common_fix[name]\n",
        "\n",
        "      if name not in stats[key]:\n",
        "        stats[key][name] = dict()\n",
        "      \n",
        "      min = i['box_score']['MIN'][k]\n",
        "      if ((not min.isnumeric()) or min == 0):\n",
        "        stats[key][name][date] = None\n",
        "        continue\n",
        "      \n",
        "      result = []\n",
        "      for c in cat:\n",
        "        result.append(extract_data(i['box_score'], c, k))\n",
        "      \n",
        "      stats[key][name][date] = result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRcGRIlcTIHt"
      },
      "outputs": [],
      "source": [
        "streaks = dict()\n",
        "stats = dict()\n",
        "create_streaks(data_train, streaks, stats)\n",
        "create_streaks(data_valid, streaks, stats)\n",
        "create_streaks(data_test, streaks, stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional Cells to view the data so far"
      ],
      "metadata": {
        "id": "aQpSq7fbyRM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streaks"
      ],
      "metadata": {
        "id": "Rr25rGzWx3iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next function creates winning streaks and win-loss records based on the map of a team's results"
      ],
      "metadata": {
        "id": "y_93db34yUx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKOpu2qLrFp6"
      },
      "outputs": [],
      "source": [
        "\n",
        "for season, teams in streaks.items():\n",
        " \n",
        "  for team, dates in teams.items():\n",
        "    if team not in final_streak:\n",
        "      final_streak[team] = dict()\n",
        "    if team not in final_record:\n",
        "      final_record[team] = dict()\n",
        "    count = 0\n",
        "    w = 0\n",
        "    l = 0\n",
        "    order = list(dates.keys())\n",
        "    order.sort()\n",
        "    for date in order:\n",
        "      result = dates[date]\n",
        "      if count * result > 0:\n",
        "        count += result\n",
        "      else:\n",
        "        count = result\n",
        "      \n",
        "      if result > 0:\n",
        "        w += 1\n",
        "      else:\n",
        "        l += 1\n",
        "      final_record[team][date] = (w, l)\n",
        "      final_streak[team][date] = count"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional Cells to view the data so far"
      ],
      "metadata": {
        "id": "yPCYMFvfyLf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh8jzAQPsNgY"
      },
      "outputs": [],
      "source": [
        "final_record"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_streak"
      ],
      "metadata": {
        "id": "SEYHS4xdysvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following dynamic data is not used because it is not effective. You can still run the code to see how it's calculated."
      ],
      "metadata": {
        "id": "AOrLV5VXyulX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74kjlu_yVL3F"
      },
      "outputs": [],
      "source": [
        "for season, players in stats.items():\n",
        " \n",
        "  for player, dates in players.items():\n",
        "    if player not in final_streak:\n",
        "      final_stats[player] = dict()\n",
        "    count = 0\n",
        "    order = list(dates.keys())\n",
        "    order.sort()\n",
        "    p = 0\n",
        "    r = 0\n",
        "    a = 0\n",
        "    g = 0\n",
        "    avg_p = None\n",
        "    avg_r = None\n",
        "    avg_a = None\n",
        "    for date in order:\n",
        "      result = dates[date]\n",
        "      t1 = (avg_p, avg_r, avg_a)\n",
        "      if result != None:\n",
        "        g += 1\n",
        "        p += result[0]\n",
        "        a += result[1]\n",
        "        r += result[2]\n",
        "        avg_p = p/g\n",
        "        avg_r = r/g\n",
        "        avg_a = a/g\n",
        "      \n",
        "      t2 = (avg_p, avg_r, avg_a)\n",
        "      final_stats[player][date] = (t1, t2)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h_2_6xmWoEa"
      },
      "outputs": [],
      "source": [
        "final_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. **Stage 1 of Model: SELECT**"
      ],
      "metadata": {
        "id": "Vw_lNBHly6R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section includes the specific pre-processing and running of the first stage of the model. Both stages of the model can be trained and evaluated independently.\n",
        "\n",
        "This stage includes the binary classifier to pick which rows of the box_score should be included in the summary"
      ],
      "metadata": {
        "id": "1GdZGS8WzBxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional if you want to check the data before running the code.\n",
        "\n"
      ],
      "metadata": {
        "id": "amQv6vkbzqID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "kUdFpTVCyGnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Data Processing"
      ],
      "metadata": {
        "id": "4XRMVBeFzziq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section converts the player names to categorical ids before training the binary classifier on the input vectors."
      ],
      "metadata": {
        "id": "IkaA7CoLz7Gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather than using a random categorical variable, the categorical id has an inverse relationship with how often a player is mentioned in the summary. Players who are mentioned more often have higher ids."
      ],
      "metadata": {
        "id": "mUjPtzsu0F9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQTXAALt0eax"
      },
      "outputs": [],
      "source": [
        "# Counts how often a player is mentioned in the summary\n",
        "reverse_mention = dict()\n",
        "for player in mentioned.keys():\n",
        "  count = mentioned[player]\n",
        "  if count not in reverse_mention:\n",
        "    reverse_mention[count] = [player]\n",
        "  else:\n",
        "    reverse_mention[count].append(player)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj6YlmqK00qf"
      },
      "outputs": [],
      "source": [
        "keys = list(reverse_mention.keys())\n",
        "keys.sort()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brckbiAV1Vc7"
      },
      "outputs": [],
      "source": [
        "# Creates mapping of player name to id.\n",
        "index = 0\n",
        "final_map = dict()\n",
        "reverse_final_map = dict()\n",
        "for key in keys:\n",
        "  for player in reverse_mention[key]:\n",
        "    final_map[player] = index\n",
        "    reverse_final_map[index] = player\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSXp_gFw1tv2"
      },
      "outputs": [],
      "source": [
        "# Add static data if present and replaces the player name with a categorical id\n",
        "for i in range(len(X)):\n",
        "  season = X[i][7]\n",
        "  X[i].pop()\n",
        "  name = X[i][0]\n",
        "  rookie = 0\n",
        "  all_star = 0\n",
        "  if name in draft[season]:\n",
        "    rookie = 1\n",
        "  if name in all_stars[season]:\n",
        "    all_star = 1\n",
        "  X[i].extend([rookie, all_star])\n",
        "  X[i][0] = final_map[X[i][0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQcLfQBvsRs0"
      },
      "outputs": [],
      "source": [
        "# Converts the data to an array before passing it to the classifier\n",
        "import numpy as np\n",
        "X_arr = np.asarray(X)\n",
        "Y_arr = np.asarray(Y)\n",
        "print(X_arr.shape, Y_arr.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Binary Classifier"
      ],
      "metadata": {
        "id": "Tm7JHHTz0wAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This stage of the model involves training the model on various classifiers and evaluating to see what's the best. Random Forest was marginally the best classifier."
      ],
      "metadata": {
        "id": "p4A8Zc-g02ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test split of 80/20"
      ],
      "metadata": {
        "id": "8dNn4wE71KWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CITATIONS**\n",
        "\n",
        "* https://maciejzalwert.medium.com/decision-tree-random-forest-and-xgboost-demystified-with-python-code-7060621eb783\n",
        "* https://scikit-learn.org/stable/"
      ],
      "metadata": {
        "id": "Y0MLj3vNHf2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxLkQuWhs-h_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_arr, Y_arr, test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Decision Trees we try to find the max depth for optimal fitting"
      ],
      "metadata": {
        "id": "zDq07GZd1N1A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeWyABmDtY_N"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ34eaNvthVE"
      },
      "outputs": [],
      "source": [
        "max_score = 0\n",
        "n_est = 0\n",
        "for i in range (1, 21):\n",
        "  classifier = DecisionTreeClassifier(max_depth = i)\n",
        "  classifier.fit(X_train, Y_train)\n",
        "  score = classifier.score(X_test, Y_test)\n",
        "  if (score > max_score):\n",
        "    max_score = score\n",
        "    n_est = i\n",
        "print(n_est, max_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-_SfKGSus5u"
      },
      "source": [
        "For Random Forest we try to find the max depth and max features for optimal fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbzlADDUuDpZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9mabLqLuXa0"
      },
      "outputs": [],
      "source": [
        "max_features = ['sqrt', 'log2', None]\n",
        "max_score = 0\n",
        "n_est = 0\n",
        "feature = ''\n",
        "for i in range (1, 21):\n",
        "\n",
        "  for max_feature in max_features:\n",
        "    classifier = RandomForestClassifier(max_depth = i, max_features=max_feature)\n",
        "    classifier.fit(X_train, Y_train)\n",
        "    score = classifier.score(X_test, Y_test)\n",
        "    if score > max_score:\n",
        "      max_score = score\n",
        "      feature = max_feature\n",
        "      n_est = i\n",
        "print(n_est, feature, max_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For XGBoost we use the xgboost package itself to find the optimal record."
      ],
      "metadata": {
        "id": "dl8YJUYu1miJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frGcRHlOw7aS"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sITzeLFxYbj"
      },
      "outputs": [],
      "source": [
        "classifer = xgb.XGBClassifier()\n",
        "classifier.fit(X_train, Y_train)\n",
        "classifier.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Data Post-Processing"
      ],
      "metadata": {
        "id": "wIpA6tHo1w3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to run both stages of the model we need to convert the categorical features back to player names for the text generation."
      ],
      "metadata": {
        "id": "-cEMsiET11E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X)):\n",
        "  X[i].pop()\n",
        "  X[i].pop()\n",
        "  X[i][0] = reverse_final_map[X[i][0]]"
      ],
      "metadata": {
        "id": "VmTELYzG2AzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Stage 2 of the Model (GENERATE)"
      ],
      "metadata": {
        "id": "fnYcgSLb2Ojd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section includes the specific pre-processing and running of the second stage of the model. Both stages of the model can be trained and evaluated independently.\n",
        "\n",
        "This stage includes the pre-trained large language model to generate text from a given box score.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XqQfUu923yEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional if you want to check the data before running the code."
      ],
      "metadata": {
        "id": "Q27jTbRf3w9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X2[0]"
      ],
      "metadata": {
        "id": "mqlmtGgU3baM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Data Pre-processing"
      ],
      "metadata": {
        "id": "9dKmSB6-40Wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we convert box score data to dummy summaries so we can work in a sequence-to-sequence setting with only lexical data."
      ],
      "metadata": {
        "id": "1MPrcghh43v-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two functions create dummy sentences out of the box score data."
      ],
      "metadata": {
        "id": "FqzNcwds39HV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFkP39oYENyn"
      },
      "outputs": [],
      "source": [
        "def get_record(record):\n",
        "  if record is None:\n",
        "    return ''\n",
        "  return \" (\" + str(record[0]) + \"-\" + str(record[1]) + \") \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvZljKQgCQBh"
      },
      "outputs": [],
      "source": [
        "# If static and dynamic data is not being used, these parameters should be set to False\n",
        "def convert_dummy(teams, x2, use_static = True, use_dynamic = True):\n",
        "  date = teams[4]\n",
        "  if use_static:\n",
        "    drft = draft[teams[5]]\n",
        "    allstr = all_stars[teams[5]]\n",
        "  else:\n",
        "    drft = []\n",
        "    allstr = []\n",
        "    \n",
        "  if use_dynamic:\n",
        "    win_record = final_record[teams[0]][date]\n",
        "    loss_record = final_record[teams[1]][date]\n",
        "    win_streak = final_streak[teams[0]][date]\n",
        "    loss_streak = final_streak[teams[1]][date]\n",
        "  else:\n",
        "    win_record = None\n",
        "    loss_record = None\n",
        "    win_streak = 0\n",
        "    loss_streak = 0\n",
        "\n",
        "  summary = \"The \" + teams[0] + get_record(win_record) + \" defeated the \" + teams[1] + get_record(loss_record) + \" \" + str(teams[2]) + \" - \" + str(teams[3]) + ' . '\n",
        "\n",
        "  if win_streak >= 2:\n",
        "    summary += teams[0] + \" are on a \" + str(win_streak) + \" game winning streak. \"\n",
        "  \n",
        "  if loss_streak <= -2:\n",
        "    summary += teams[1] + \" are on a \" + str(-loss_streak) + \" game losing streak. \"\n",
        "  \n",
        "  for row in x2:\n",
        "    name = row[0]\n",
        "    if name in allstr:\n",
        "      name = 'All-Star ' + name\n",
        "      \n",
        "    elif name in drft:\n",
        "      name = 'rookie ' + name\n",
        "    \n",
        "    summary += ' ' + name + ' had ' \n",
        "    # We always include points, rebounds, assists\n",
        "    # We only include steals, blocks, turnovers \n",
        "    # when they're above 5\n",
        "    # I found these are the optimal thresholds to reduce input size without\n",
        "    # losing model results\n",
        "    if row[1] >= 0:\n",
        "      summary += str(row[1]) + ' points ' + ' , ' \n",
        "    if row[2] >= 0:\n",
        "      summary += str(row[2]) + ' rebounds ' + ' , ' \n",
        "    if row[3] >= 0:\n",
        "      summary += str(row[3]) + ' assists ' + ' , '\n",
        "    if row[4] >= 5:\n",
        "      summary += str(row[4]) + ' steals ' + ' , '\n",
        "    if row[5] >= 5:\n",
        "      summary += str(row[5]) + ' blocks ' + ' , '\n",
        "    if row[6] >= 5:\n",
        "      summary += str(row[6]) + ' turnovers '\n",
        "    summary +=  '.'\n",
        "  return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P0e6y-UDJqF"
      },
      "outputs": [],
      "source": [
        "# create a list of dummy summaries to be fed into the LLM\n",
        "X2_processed = []\n",
        "for i in range(len(X2)):\n",
        "  X2_processed.append(convert_dummy(X2[i][0], X2[i][1:], False, False))\n",
        "print(len(X2_processed))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional if you want to see the results before running the second stage of the model"
      ],
      "metadata": {
        "id": "2M00woJP4tZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECAMgd7PMCVx"
      },
      "outputs": [],
      "source": [
        "X2_processed[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC-gwCb9FkfO"
      },
      "outputs": [],
      "source": [
        "Y2[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Large Language Model"
      ],
      "metadata": {
        "id": "CKHrRxkX5BFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use a pre-trained large language model to generate human-like game summaries from our dummy summaries"
      ],
      "metadata": {
        "id": "kAY6zH4w5Xpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CITATIONS**\n",
        "* https://huggingface.co/docs/transformers/\n",
        "* https://huggingface.co/transformers/v3.3.1/pretrained_models.html\n",
        "* https://github.com/huggingface/evaluate\n",
        "* https://docs.fast.ai/learner.html"
      ],
      "metadata": {
        "id": "mbmuImt1Hzxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaV4-9RzD1hH"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "!pip install ohmeow-blurr -q\n",
        "!pip install bert-score -q\n",
        "!pip install nltk\n",
        "\n",
        "import pandas as pd\n",
        "from fastai.text.all import *\n",
        "from transformers import *\n",
        "from blurr.text.data.all import *\n",
        "from blurr.text.modeling.all import *\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# START - SOURCE_REPO = https://github.com/ohmeow/blurr"
      ],
      "metadata": {
        "id": "ZkA1dST0IFSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_llm(base = 'BART', max_len = 256, max_tgt_len = 256, prefix = True, task = 'summarization', verbose = True, batch_size=2):\n",
        "\n",
        "  # Download pre-trained model\n",
        "  if base == 'BART':\n",
        "    pretrained_model_name = \"facebook/bart-base\"\n",
        "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, \n",
        "                                                                  model_cls=BartForConditionalGeneration)\n",
        "  elif base == 'T5':\n",
        "    if task == 'summarization':\n",
        "      prefix = False\n",
        "    pretrained_model_name = \"t5-base\"\n",
        "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, \n",
        "                                                                  model_cls=T5ForConditionalGeneration)\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "  # Initialize arguments for pre-trained model\n",
        "  \n",
        "  text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task=task)\n",
        "  text_gen_kwargs['max_length'] = max_len\n",
        "  if not prefix:\n",
        "    text_gen_kwargs.pop('prefix')\n",
        "  if verbose:\n",
        "    print('Args', text_gen_kwargs)\n",
        "  \n",
        "  hf_batch_tfm = Seq2SeqBatchTokenizeTransform(\n",
        "    hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_len, max_tgt_length=max_tgt_len, text_gen_kwargs=text_gen_kwargs\n",
        "  )\n",
        "  seq2seq_metrics = {\n",
        "        'rouge': {\n",
        "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
        "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
        "        },\n",
        "        'bertscore': {\n",
        "            'compute_kwargs': { 'lang': 'en' },\n",
        "            'returns': [\"precision\", \"recall\", \"f1\"]\n",
        "        },\n",
        "        'bleu': {\"returns\": \"bleu\"}\n",
        "  } \n",
        "\n",
        "  # Use FastAi's dataloader to efficiently access the data during training\n",
        "  df_X2 = pd.DataFrame(X2_processed, columns=['dummy'])\n",
        "  df_Y2 = pd.DataFrame(Y2, columns=['summary'])\n",
        "  df_data = pd.concat([df_X2, df_Y2], axis=1)\n",
        "  \n",
        "  blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=hf_batch_tfm), noop)\n",
        "  dblock = DataBlock(blocks=blocks, get_x=ColReader('dummy'), get_y=ColReader('summary'), splitter=RandomSplitter())\n",
        "\n",
        "  dls = dblock.dataloaders(df_data, bs=batch_size)\n",
        "\n",
        "  if verbose:\n",
        "    dls.show_batch(dataloaders=dls, max_n=2)\n",
        "\n",
        "  ## Initialize pre-trained model\n",
        "\n",
        "  model = BaseModelWrapper(hf_model)\n",
        "  learn_cbs = [BaseModelCallback]\n",
        "  fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
        "\n",
        "  learn = Learner(dls, \n",
        "                  model,\n",
        "                  opt_func=ranger,\n",
        "                  loss_func=CrossEntropyLossFlat(),\n",
        "                  cbs=learn_cbs,\n",
        "                  splitter=partial(blurr_seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
        "\n",
        "  learn.create_opt() \n",
        "  learn.freeze()\n",
        "\n",
        "  return learn, fit_cbs"
      ],
      "metadata": {
        "id": "-QZpyWgY5lb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIgyWSmZcIw7"
      },
      "outputs": [],
      "source": [
        "learn, fit_cbs = get_llm(base = 'BART', max_len = 256, max_tgt_len = 256, prefix = True, task = 'summarization', verbose = False, batch_size=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use FastAI's fit_one_cycle method to train and evaluate the model. It does a train/test(val) split of 80/20 and displays the results for the metrics we pass to it."
      ],
      "metadata": {
        "id": "-3rG1hXN8hyF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q68FZ0rMwcQ"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "learning_rate = 3e-5\n",
        "epochs = 1 # For ease of checking the code\n",
        "learn.fit_one_cycle(epochs, lr_max=learning_rate, cbs=fit_cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ix6mNK2-haR"
      },
      "outputs": [],
      "source": [
        "# See sample output\n",
        "learn.show_results(learner=learn, max_n=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END - SOURCE REPO = https://github.com/ohmeow/blurr"
      ],
      "metadata": {
        "id": "pWqwA6dqITXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 BERT Model"
      ],
      "metadata": {
        "id": "FarFKllm88Mi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# START - SOURCE REPO = https://huggingface.co/docs/transformers/model_doc/bert-generation"
      ],
      "metadata": {
        "id": "KSJrmJ57ImWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also experimented with a BERT model, but the loss never reduced so I never completed it. You can still try the training loop."
      ],
      "metadata": {
        "id": "rrD7v-_z8_m7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib7SPiraGAtT"
      },
      "outputs": [],
      "source": [
        "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer\n",
        "\n",
        "encoder = BertGenerationEncoder.from_pretrained(\"bert-base-uncased\", bos_token_id=101, eos_token_id=102)\n",
        "decoder = BertGenerationDecoder.from_pretrained(\"bert-base-uncased\", add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102)\n",
        "bert2bert = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuW_pbTyG1jR"
      },
      "outputs": [],
      "source": [
        "avg_loss = 0\n",
        "count = 20\n",
        "bert2bert.train()\n",
        "for i in range(len(X2_processed)):\n",
        "  input_ids = tokenizer(X2_processed[i], add_special_tokens=True, return_tensors=\"pt\").input_ids\n",
        "  labels = tokenizer(Y2[i], add_special_tokens=True, return_tensors=\"pt\").input_ids\n",
        "  try:\n",
        "    loss = bert2bert(input_ids=input_ids, decoder_input_ids=labels, labels=labels).loss\n",
        "    avg_loss += loss.item()\n",
        "    loss.backward()\n",
        "  except RuntimeError:\n",
        "    count -= 1\n",
        "\n",
        "  if (i+1)%20 == 0:\n",
        "    print(i)\n",
        "    print('Loss', avg_loss/count)\n",
        "    avg_loss = 0\n",
        "    count = 20\n",
        "  \n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc1cMy-Rg9ay"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer(X2_processed[1000], add_special_tokens=True, return_tensors=\"pt\").input_ids\n",
        "bert2bert.generate(input_ids, decoder_start_token_id=bert2bert.config.decoder.pad_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaYLg4NEoxQh"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(bert2bert.generate(input_ids, decoder_start_token_id=bert2bert.config.decoder.pad_token_id)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END - SOURCE REPO = https://huggingface.co/docs/transformers/model_doc/bert-generation"
      ],
      "metadata": {
        "id": "bh76KsEgIxN0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8hSFZ9L97/wUj3anjtYVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}